# docker compose file for running a 3-node PostgreSQL cluster
# with 3-node etcd cluster as the DCS and one haproxy node
#
# requires a patroni image build from the Dockerfile:
# $ docker build -t patroni .
# The cluster could be started as:
# $ docker-compose up -d
# You can read more about it in the:
# https://github.com/zalando/patroni/blob/master/docker/README.md
version: "2"

networks:
    demo:

services:
    etcd1: &etcd
        image: ${PATRONI_TEST_IMAGE:-patroni.original}
        networks: [ demo ]
        environment:
            ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
            ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
            ETCD_INITIAL_CLUSTER: etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380
            ETCD_INITIAL_CLUSTER_STATE: new
            ETCD_INITIAL_CLUSTER_TOKEN: tutorial
            ETCD_UNSUPPORTED_ARCH: arm64
        container_name: demo-etcd1
        hostname: etcd1
        command: etcd --name etcd1 --initial-advertise-peer-urls http://etcd1:2380

    etcd2:
        <<: *etcd
        container_name: demo-etcd2
        hostname: etcd2
        command: etcd --name etcd2 --initial-advertise-peer-urls http://etcd2:2380

    etcd3:
        <<: *etcd
        container_name: demo-etcd3
        hostname: etcd3
        command: etcd --name etcd3 --initial-advertise-peer-urls http://etcd3:2380

    haproxy:
        image: ${PATRONI_TEST_IMAGE:-patroni.original}
        networks: [ demo ]
        env_file: docker/patroni.env
        hostname: haproxy
        container_name: demo-haproxy
        ports:
            - "5000:5000"
            - "5001:5001"
        command: haproxy
        environment: &haproxy_env
            ETCDCTL_ENDPOINTS: http://etcd1:2379,http://etcd2:2379,http://etcd3:2379
            PATRONI_ETCD3_HOSTS: "'etcd1:2379','etcd2:2379','etcd3:2379'"
            PATRONI_SCOPE: demo

    patroni1:
        image: ${PATRONI_TEST_IMAGE:-patroni}
        networks: [ demo ]
        env_file: docker/patroni.env
        hostname: patroni1
        container_name: demo-patroni1
        environment:
            <<: *haproxy_env
            PATRONI_NAME: patroni1
        volumes:
          - postgres1_data:/home/postgres/data:z
          - ./docker/patroni/postgres0.yml:/home/postgres/postgres0.yml:z
          - ./docker/patroni/setup_cluster.sh:/usr/local/bin/setup_cluster.sh:z
          - ./docker/patroni/init.sql:/home/postgres/init.sql:z

    patroni2:
        image: ${PATRONI_TEST_IMAGE:-patroni}
        networks: [ demo ]
        env_file: docker/patroni.env
        hostname: patroni2
        container_name: demo-patroni2
        environment:
            <<: *haproxy_env
            PATRONI_NAME: patroni2
        volumes:
          - postgres2_data:/home/postgres/data:z
          - ./docker/patroni/postgres0.yml:/home/postgres/postgres0.yml:z
          - ./docker/patroni/setup_cluster.sh:/usr/local/bin/setup_cluster.sh:z
          - ./docker/patroni/init.sql:/home/postgres/init.sql:z

    patroni3:
        image: ${PATRONI_TEST_IMAGE:-patroni}
        networks: [ demo ]
        env_file: docker/patroni.env
        hostname: patroni3
        container_name: demo-patroni3
        environment:
            <<: *haproxy_env
            PATRONI_NAME: patroni3
        volumes:
          - postgres3_data:/home/postgres/data:z
          - ./docker/patroni/postgres0.yml:/home/postgres/postgres0.yml:z
          - ./docker/patroni/setup_cluster.sh:/usr/local/bin/setup_cluster.sh:z
          - ./docker/patroni/init.sql:/home/postgres/init.sql:z

    kafka:
        image: apache/kafka:3.7.0
        networks: [ demo ]
        restart: unless-stopped
        container_name: kafka
        hostname: kafka
        ports:
          - "9092:9092"
        volumes:
          - kafka_data:/var/lib/kafka:z
        environment:
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
            KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka:29092,PLAINTEXT_HOST://127.0.0.1:9092'
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_PROCESS_ROLES: 'broker,controller'
            KAFKA_NODE_ID: 1
            KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
            KAFKA_LISTENERS: 'INTERNAL://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://:9092'
            KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
            KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
            KAFKA_LOG_DIRS: "/var/lib/kafka/data"
            # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
            # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
            CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'

    # https://hub.docker.com/r/debezium/connect
    connect:
        build: ./docker/connect
        networks: [ demo ]
        restart: unless-stopped
        container_name: connect
        hostname: connect
        ports:
          - 8083:8083

        environment:
            BOOTSTRAP_SERVERS: kafka:29092
            GROUP_ID: 1
            CONFIG_STORAGE_TOPIC: my_connect_configs
            OFFSET_STORAGE_TOPIC: my_connect_offsets
            STATUS_STORAGE_TOPIC: my_connect_statuses
    create-debezium-connectors:
        image: curlimages/curl:8.6.0
        networks: [ demo ]
        container_name: create-debezium-connectors
        hostname: create-debezium-connectors
        restart: on-failure
        volumes:
          - ./docker/create-debezium-connectors:/opt/create-debezium-connectors:z
        entrypoint: ['/bin/sh', '/opt/create-debezium-connectors/create.sh']
    clickhouse:
        image: clickhouse/clickhouse-server:23.11.5.29-alpine
        networks: [ demo ]
        container_name: clickhouse
        hostname: clickhouse
        restart: unless-stopped
        ports:
          - "8123:8123"
 #         - "9000:9000"
        volumes:
          - clickhouse_data:/var/lib/clickhouse:z
          - ./docker/clickhouse/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d:z
        ulimits:
            nofile:
              soft: 262144
              hard: 262144

volumes:
    postgres1_data:
    postgres2_data:
    postgres3_data:
    kafka_data:
    clickhouse_data:


